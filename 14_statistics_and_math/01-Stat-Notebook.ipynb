{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Californian Housing Prices with Regression Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "from sklearn.linear_model import LinearRegression \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the California housing dataset\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "housing_data = data.frame\n",
    "\n",
    "# Display the first few rows\n",
    "print(housing_data.head())\n",
    "\n",
    "# Save locally if needed\n",
    "housing_data.to_csv(\"housing_data.csv\", index=False)\n",
    "\n",
    "# Basic info about the dataset\n",
    "print(housing_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- INFO--\")\n",
    "print(housing_data.info())\n",
    "\n",
    "print(\"-- DESCRIBE--\")\n",
    "print(housing_data.describe())\n",
    "\n",
    "housing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visulizing Price Using Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a base map centered on California\n",
    "california_map = folium.Map(location=[housing_data[\"Latitude\"].mean(), housing_data[\"Longitude\"].mean()], \n",
    "                            zoom_start=6)\n",
    "\n",
    "# Add a heat map layer for MedHouseVal\n",
    "heat_data = [\n",
    "    [row['Latitude'], row['Longitude'], row['MedHouseVal']] \n",
    "    for _, row in housing_data.iterrows()\n",
    "]\n",
    "\n",
    "HeatMap(heat_data, radius=10).add_to(california_map)\n",
    "\n",
    "# Save and display the map\n",
    "california_map.save(\"california_housing_map.html\")\n",
    "california_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation HeatMap\n",
    "Looks like the Median Income is largely corrolated with the price of the house. This makes sense as people with higher income also tends to afford the most expensive houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# Correlation Variables. \n",
    "correlation_matrix = housing_data.corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar=True)\n",
    "plt.title(\"Correlation Matrix of Housing Data\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = housing_data[['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']]\n",
    "y = housing_data['MedHouseVal']\n",
    "\n",
    "model =  LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Model summary\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"R² Score:\", r2_score(y_test, predictions))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot of Actual vs. Predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.6, color='blue', label='Predicted vs Actual')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', linewidth=2, label='Perfect Fit')\n",
    "plt.title(\"Actual vs Predicted Housing Prices\")\n",
    "plt.xlabel(\"Actual Median House Value\")\n",
    "plt.ylabel(\"Predicted Median House Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Residuals calculation\n",
    "\n",
    "residuals = y_test - predictions\n",
    "\n",
    "# Residuals scatter plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot 1: Residuals vs Predicted Values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(predictions, residuals, alpha=0.6, color='purple', label='Residuals')\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Zero Residual Line')\n",
    "plt.title(\"Residuals vs Predicted Values\")\n",
    "plt.xlabel(\"Predicted Median House Value\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Subplot 2: Histogram and KDE of Residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(residuals, kde=True, bins=100, color='blue', label='Residuals Distribution')\n",
    "plt.axvline(residuals.mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "plt.title(\"Histogram and KDE of Residuals\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Shapiro-Wilk test for normality\n",
    "stat, p = shapiro(residuals)\n",
    "if p > 0.05:\n",
    "    print(f\"Shapiro-Wilk Test: p-value = {p:.10f} (Residuals are normally distributed)\")\n",
    "else:\n",
    "    print(f\"Shapiro-Wilk Test: p-value = {p:.10f} (Residuals are not normally distributed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals are Normally distrubuted bot not centered around Zero (Indicating Bias) \n",
    "\n",
    "\t•\tThe residuals show an overall normal distribution symmetry but are not centered around zero, it hints to bias in the model.\n",
    "\t•\tThis bias suggests that the model is systematically overestimating or underestimating \n",
    "\t•\tA better fit could potentially be achieved by adjusting the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  - Comparing The Performance Of Different Regression Models\n",
    "\n",
    "\tRegression Models to Test:\n",
    "\t•\tLinear Regression\n",
    "\t•\tRidge Regression\n",
    "\t•\tLasso Regression\n",
    "\t•\tDecision Tree Regression\n",
    "\t•\tRandom Forest Regression\n",
    "\tMetrics for Comparison:\n",
    "\t•\t R^2  Score\n",
    "\t•\tMean Squared Error (MSE)\n",
    "\t•\tResidual Analysis (to check the error distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming `housing_data` is your dataset\n",
    "X = housing_data[['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']]\n",
    "y = housing_data['MedHouseVal']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    residuals = y_test - predictions\n",
    "\n",
    "    # Normality test for residuals\n",
    "    shapiro_stat, shapiro_p = shapiro(residuals)\n",
    "    normality = \"Yes\" if shapiro_p > 0.05 else \"No\"\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"Model\": model,\n",
    "        \"R2\": r2,\n",
    "        \"MSE\": mse,\n",
    "        \"Residuals\": residuals,\n",
    "        \"Shapiro-Wilk P-Value\": shapiro_p,\n",
    "        \"Residuals Normally Distributed\": normality\n",
    "    }\n",
    "\n",
    "# Visualize results\n",
    "fig, axs = plt.subplots(len(models), 3, figsize=(18, 20))\n",
    "\n",
    "for i, (name, result) in enumerate(results.items()):\n",
    "    predictions = result[\"Model\"].predict(X_test)\n",
    "    residuals = result[\"Residuals\"]\n",
    "\n",
    "    # Predicted vs Actual\n",
    "    axs[i, 0].scatter(y_test, predictions, alpha=0.6, label=\"Predicted vs Actual\")\n",
    "    axs[i, 0].plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", linestyle=\"--\", label=\"Perfect Fit\")\n",
    "    axs[i, 0].set_title(f\"{name} - Predicted vs Actual\")\n",
    "    axs[i, 0].set_xlabel(\"Actual\")\n",
    "    axs[i, 0].set_ylabel(\"Predicted\")\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    # Residuals scatter plot\n",
    "    axs[i, 1].scatter(predictions, residuals, alpha=0.6, label=\"Residuals\")\n",
    "    axs[i, 1].axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    axs[i, 1].set_title(f\"{name} - Residuals\")\n",
    "    axs[i, 1].set_xlabel(\"Predicted\")\n",
    "    axs[i, 1].set_ylabel(\"Residuals\")\n",
    "    axs[i, 1].legend()\n",
    "\n",
    "    # Residuals histogram and KDE\n",
    "    sns.histplot(residuals, kde=True, ax=axs[i, 2], color=\"blue\", bins=30, alpha=0.7, label=\"Residuals Distribution\")\n",
    "    axs[i, 2].set_title(f\"{name} - Residuals Distribution\")\n",
    "    axs[i, 2].set_xlabel(\"Residuals\")\n",
    "    axs[i, 2].set_ylabel(\"Frequency\")\n",
    "    axs[i, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": [name for name in results.keys()],\n",
    "    \"R2 Score\": [result[\"R2\"] for result in results.values()],\n",
    "    \"MSE\": [result[\"MSE\"] for result in results.values()],\n",
    "    \"Shapiro-Wilk P-Value\": [result[\"Shapiro-Wilk P-Value\"] for result in results.values()],\n",
    "    \"Residuals Normally Distributed\": [result[\"Residuals Normally Distributed\"] for result in results.values()]\n",
    "})\n",
    "\n",
    "# Display results table\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Optional visualization of final performance comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "comparison_df.set_index(\"Model\")[[\"R2 Score\", \"MSE\"]].plot(kind=\"bar\", ax=ax, alpha=0.7)\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Testing More ML Models And Comparing Performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming `housing_data` is your dataset\n",
    "X = housing_data[['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']]\n",
    "y = housing_data['MedHouseVal']\n",
    "\n",
    "# Reduce dataset size for testing (optional)\n",
    "# Uncomment the line below for faster testing\n",
    "# X, y = X.sample(5000, random_state=42), y.sample(5000, random_state=42)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models with optimized parameters\n",
    "ml_models = {\n",
    "   # \"Support Vector Regression\": SVR(kernel='linear', C=1.0),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42, n_estimators=50, max_depth=3),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, n_estimators=50, max_depth=3, verbosity=0, n_jobs=-1),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42, iterations=50, depth=3)\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "ml_results = {}\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in ml_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    residuals = y_test - predictions\n",
    "\n",
    "    # Normality test for residuals\n",
    "    shapiro_stat, shapiro_p = shapiro(residuals)\n",
    "    normality = \"Yes\" if shapiro_p > 0.05 else \"No\"\n",
    "\n",
    "    # Store results\n",
    "    ml_results[name] = {\n",
    "        \"Model\": model,\n",
    "        \"R2\": r2,\n",
    "        \"MSE\": mse,\n",
    "        \"Residuals\": residuals,\n",
    "        \"Shapiro-Wilk P-Value\": shapiro_p,\n",
    "        \"Residuals Normally Distributed\": normality\n",
    "    }\n",
    "\n",
    "# Visualize results\n",
    "fig, axs = plt.subplots(len(ml_models), 3, figsize=(18, 20))\n",
    "\n",
    "for i, (name, result) in enumerate(ml_results.items()):\n",
    "    predictions = result[\"Model\"].predict(X_test)\n",
    "    residuals = result[\"Residuals\"]\n",
    "\n",
    "    # Predicted vs Actual\n",
    "    axs[i, 0].scatter(y_test, predictions, alpha=0.6, label=\"Predicted vs Actual\")\n",
    "    axs[i, 0].plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", linestyle=\"--\", label=\"Perfect Fit\")\n",
    "    axs[i, 0].set_title(f\"{name} - Predicted vs Actual\")\n",
    "    axs[i, 0].set_xlabel(\"Actual\")\n",
    "    axs[i, 0].set_ylabel(\"Predicted\")\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    # Residuals scatter plot\n",
    "    axs[i, 1].scatter(predictions, residuals, alpha=0.6, label=\"Residuals\")\n",
    "    axs[i, 1].axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    axs[i, 1].set_title(f\"{name} - Residuals\")\n",
    "    axs[i, 1].set_xlabel(\"Predicted\")\n",
    "    axs[i, 1].set_ylabel(\"Residuals\")\n",
    "    axs[i, 1].legend()\n",
    "\n",
    "    # Residuals histogram and KDE\n",
    "    sns.histplot(residuals, kde=True, ax=axs[i, 2], color=\"blue\", bins=30, alpha=0.7, label=\"Residuals Distribution\")\n",
    "    axs[i, 2].set_title(f\"{name} - Residuals Distribution\")\n",
    "    axs[i, 2].set_xlabel(\"Residuals\")\n",
    "    axs[i, 2].set_ylabel(\"Frequency\")\n",
    "    axs[i, 2].legend()\n",
    "    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "ml_comparison_df = pd.DataFrame({\n",
    "    \"Model\": [name for name in ml_results.keys()],\n",
    "    \"R2 Score\": [result[\"R2\"] for result in ml_results.values()],\n",
    "    \"MSE\": [result[\"MSE\"] for result in ml_results.values()],\n",
    "    \"Shapiro-Wilk P-Value\": [result[\"Shapiro-Wilk P-Value\"] for result in ml_results.values()],\n",
    "    \"Residuals Normally Distributed\": [result[\"Residuals Normally Distributed\"] for result in ml_results.values()]\n",
    "})\n",
    "\n",
    "# Display results table\n",
    "print(\"ML Model Performance Comparison:\")\n",
    "print(ml_comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "14-statistics-and-math-O9BsplZE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
